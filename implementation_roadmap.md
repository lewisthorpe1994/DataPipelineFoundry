
# Detailed Implementation Roadâ€‘Map  
*A soloâ€‘developer guide to shipping the first usable release of **FlowForgery** (working title â€œFletch/Forgeâ€)*  

> **Assumptions**  
> * You have the workspace skeleton (`crates/cli`, `ff_core`, `adapter_postgres`, `engine_df`, `parser`).  
> * Youâ€™re comfortable with ğŸ¤– nightlyâ€“ish hours (5â€“8â€¯h/wk).  
> * Target **RustÂ 2021**, stable toolâ€‘chain.  

---

## PhaseÂ 0 â€” Workspace BootstrappingÂ (Â½Â day)

| Task | Command / File | Notes |
|------|----------------|-------|
| Create workspace manifest | *root* `Cargo.toml` | `[workspace] resolver = "2"` plus members list. |
| Create crates | `cargo new --bin crates/cli`, etc. | Use `ff_core` (avoid stdlib *core* clash). |
| Shared lint / CI | `.cargo/config.toml` | `rustflags = ["-Dwarnings"]` & incremental build. |
| GitHub Actions | `.github/workflows/ci.yml` | Matrix: `cargo check`, `cargo test`, `clippy`. |

*Deliverable*: `cargo check` passes; CI green.

---

## PhaseÂ 1 â€” CLI SkeletonÂ (1Â day)

1. **Add `clap`** to `crates/cli/Cargo.toml`  

   ```toml
   clap = { version = "4", features = ["derive"] }
   ```

2. **Define topâ€‘level commands** in `main.rs`

   ```rust
   #[derive(Parser)]
   #[command(name = "forgery")]
   enum Cmd {{
       Init {{ path: Option<PathBuf> }},
       Compile,
       Run {{
           #[arg(short, long, default_value = "postgres")]
           target: String,
       }},
       Graph,
       Clean,
   }}
   ```

3. **Stub each handler** to `println!("not impl yet")`.  
4. **Wire logging** (`env_logger`) so `RUST_LOG=debug forgery compile` is possible.

*Deliverable*: `forgery --help` shows usage.

---

## PhaseÂ 2 â€” `init` CommandÂ (1Â day)

| Step | Implementation hint |
|------|---------------------|
| Create project dir | `std::fs::create_dir_all(path.join("models"))` |
| Scaffold `project.yml` | Use `include_str!("../templates/project.yml")`. Fill `name` with CLI arg or folder name. |
| Add sample model | `models/example.sql` â†’ `SELECT 1 AS id;` |
| Safeguards | If path exists & nonâ€‘empty â†’ prompt `--force`. |

*Tests*: `cargo test -p cli` â†’ run `init` in tempdir, assert files exist.

---

## PhaseÂ 3 â€” Config Loader (`ff_core`) (1â€¯Â½Â days)

| Module | Responsibilities |
|--------|------------------|
| `config` | Struct `ProjectConfig {{ name, default_schema, models_path }}`; parse with `serde_yaml`. |
| `model`  | Struct `{{ name, sql }}`; load `.sql` files, store raw text. |
| `dag`    | Build dependency graph using `petgraph::Graph`. Simple regex `\{{\s*ref\(['"](.+?)['"]\)\s*\}}`. |
| `compiler` | `fn compile(project_dir) -> Vec<CompiledModel>` writing to `target/`. |

*Unit tests*:  
- Parsing invalid YAML returns error.  
- DAG builder orders `a.sql` â†’ `b.sql` if `ref('a')` found.

---

## PhaseÂ 4 â€” `compile` CommandÂ (2Â days)

1. Call `ff_core::compiler::compile()`.  
2. Write each rendered SQL to `target/models/{{name}}.sql`.  
3. Produce `target/manifest.json` (`serde_json`).

*CLIÂ UX*:  

```bash
forgery compile
# âœ Compiled 4 models in 120â€¯ms
```

---

## PhaseÂ 5 â€” Postgres Adapter (`adapter_postgres`) (2â€¯days)

| Component | Implementation |
|-----------|----------------|
| Trait | In `ff_core::adapter::Adapter` with `async fn execute(&self, sql: &str)`. |
| Impl | `AdapterPostgres::new(conn_str)` using `tokio_postgres`. |
| Transaction | For each model: `BEGIN; CREATE TABLE IF NOT EXISTS target_schema.model AS (...); COMMIT;` |
| Logging | Record rows affected via `row_count()` if possible. |

**Integration test** (uses `#[tokio::test]` + `docker run --rm -p 5432:5432 postgres:16-alpine`). Skip on CI if `$POSTGRES_URL` not set.

---

## PhaseÂ 6 â€” `run` Command with Postgres TargetÂ (1â€¯day)

1. Load manifest JSON for runâ€‘order.  
2. Instantiate `AdapterPostgres`.  
3. Loop models; call `adapter.execute(compiled_sql)`.  
4. On error: abort loop, exit nonâ€‘zero.  
5. Fancy log:

```
â— model_customers â€¦  OK  (1.37â€¯s)
â— model_orders     â€¦  OK  (0.59â€¯s)
```

---

## PhaseÂ 7 â€” DataFusion Engine (`engine_df`) (3â€¯days)

| Task | How |
|------|-----|
| Feature flag | `forgery run --target datafusion --data ./parquet` |
| Session | `let mut ctx = SessionContext::new();` |
| Register data | Glob register: for every file under `--data`, create `ctx.register_parquet("tbl", path, ParquetReadOptions::default())`. |
| Execute | `ctx.sql(&compiled_sql).await?.collect().await?;` |
| Output | Save tables to `--output` as Parquet (`datafusion::arrow::ipc::writer`). |

*Edge cases*: If compiled SQL uses `CREATE TABLE`, wrap whole text in `SELECT * FROM (...) AS t` to capture results (MVP hack).

---

## PhaseÂ 8 â€” `graph` & `clean` (Â¾â€¯day)

* `graph` : Print `petgraph::dot::Dot(&dag)` or simple ASCII.  
* `clean` : Remove `target/` directory.

---

## PhaseÂ 9 â€” Packaging & Release (1â€¯day)

| Step | Tool |
|------|------|
| Static builds | `cargo dist --tag v0.1.0` |
| Checksums & sigs | autoâ€‘generated by cargoâ€‘dist |
| Release notes | Include install curlâ€‘pipeâ€‘sh snippet (`cargo-dist install.sh`). |

---

## PhaseÂ 10 â€” Optional Polish (Backlog)

- Add `--select` model filters.  
- Incremental materialisations (`INSERT WHERE NOT EXISTS`).  
- Unitâ€‘test helpers in `ff_core::testing`.  
- VSÂ Code syntax/manifest snippets.

---

### Timeline Summary (â‰ˆâ€¯12Â developer days â‰ˆ 6â€¯weeks at 2â€¯eve/wk)

| Week | Feature done |
|------|--------------|
| 1 | Workspace, CLI skeleton, `init` |
| 2 | Config loader, DAG, `compile` |
| 3 | Postgres adapter, `run` (PG) |
| 4 | DataFusion engine, `run` (local) |
| 5 | `graph`, `clean`, endâ€‘toâ€‘end tests |
| 6 | Packaging & first GitHub release |

---

## Implementation Order Cheatsheet

```
CLI::Init   â†’ ff_core::config
            â†’ ff_core::dag
CLI::Compile â†’ ff_core::compiler
CLI::Run(pg)â†’ adapter_postgres
CLI::Run(df)â†’ engine_df
```

Stick religiously to *one pullâ€‘request per milestone* â€” easier reviews, quicker rollbacks.

---

*GeneratedÂ 2025-06-02*
